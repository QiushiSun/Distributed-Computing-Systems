# Chapter3 MapReduce

1. **MapReduce与MPI相比所具备的优势是什么？**

   - MapReduce将分布式程序的通讯接口进行了封装，因此减轻了程序员的工作量，降低了编程难度；
   - MapReduce提供容错机制，而MPI本身不提供，因此程序员不需要自己实现容错，提高了可靠性。

2. **请解释MapReduce的逻辑计算模型和物理计算模型。**

   逻辑计算模型：MapReduce将并行计算过程抽象为Map和Reduce两个算子，从图的角度看，MapReduce的计算模型是仅有两个顶点的DAG。

   物理计算模型：MapReduce的两个逻辑算子在物理上需要若干个实例来实现。一个算子可以同时由多个实例并行执行。

3. **MapReduce的主要部件有哪些？各个部件都有什么作用？**

   MapReduce的主要部件有JobTracker,TaksTracker,Task和客户端。

   - Job tracker 主节点运行的管理进程，负责系统的资源管理和作业job管理，将job拆分成任务task
   - Task tracker 从节点运行的后台进程，管理单个节点上的资源和任务，使用slot等量划分节点上的资源，向job tracker汇报情况
   - Task/child 可以执行Map或Reduce的任务，编码相同，所以不用区分是Map还是Reduce进程，具体使用的时候装填对应程序即可
   - Client/RunJar 用户和Map Reduce的交互接口

4. **如果不考虑数据的输入和数据输出阶段，MapReduce的工作过程可以划分为哪些阶段？通常来说哪一阶段对MapReduce程序性能的影响占据主导地位？**

   MapReduce的工作过程可以分为Map，Shuffle和Reduce三个阶段，其中，Map阶段将输入数据转化为键值对；Shuffle阶段将数据根据键值发送到不同的节点上；Reduce阶段接受数据，完成合并。

   其中，Shuffle阶段对程序性能的影响占主导地位。因为这一阶段需要等待*对应的Map节点*将数据全部写入磁盘之后才能开始，且需要网络IO，耗时较大。（Map完成+Map节点完成数量达到阈值）

5. **请简述MapReduce与HDFS之间的关系。**

   这两者都是Hadoop的重要组成部分。MapReduce是运行在HDFS上的数据处理框架，本身并不具备数据存储功能。MapReduce的输入数据来自于HDFS，输出到HDFS中。HDFS是分布式的数据存储系统，其本身不具备数据处理功能，要实现数据处理需要建立在HDFS上的各种数据处理框架，如MapReduce。

6. **MapReduce中的归并merge和合并combine有什么区别？**

   归并是在Reduce任务前，由MapReduce自动对Reduce接受的数据进行归并排序。而合并是由程序员定义，主动对数据进行合并。合并操作可以发生在Map和Reduce两个阶段的缓冲区溢写时。当程序定义了合并方法时，Reduce任务会先执行合并操作。

   因此，归并在Reduce溢写缓冲区时自动发生；合并由程序员定义，可以在Map或Reduce的溢写缓冲区时执行。

7. **MapReduce中的分布式缓存机制有什么作用？**

   在某些情况下，分布式缓存可以提高程序的运行效率。当有一部分数据量小又被大部分任务所需要，如在进行表的自然连接时，其中有一张表数据量明显较小，将它们进行shuffle的代价是比较大的。此时，如果将它们进行分布式缓存，在Map阶段直接完成连接，就可以避免shuffle，提高程序的运行效率。

8. **如果MapReduce以HDFS中的文件作为输入，那么InputFormat中的Split与HDFS中的块是否必然一一对应？为什么？**

   物理分块和逻辑分块并非是一一对应的。物理分块的依据是数据量，而逻辑分块的依据是划分的逻辑。如文件的一句话被划分在不同的物理分块中，而split的读取逻辑设置为整行读取，此时物理分块和逻辑分块就不是对应的。

9. **如果MapReduce运行过程中仅有某一Reduce任务的进程崩溃而其他部件正常，那么MapReduce系统会重启一个Reduce任务。请问重启后的Reduce任务从哪里获取输入数据？**

   重启后的Reduce任务会从对应的Map节点的本地磁盘中读取数据。

10. **假设Map任务的缓冲区“无限大”，那么是否还有必要溢写磁盘？类似地，如果Reduce任务的缓冲区“无限大”，那么是否需要溢写磁盘？为什么？**

    Map任务需要，因为溢写磁盘不仅是由于缓冲区不够大，同时也是为了进行容错。当Reduce节点发生故障导致数据丢失时，需要从对应的Map节点读取数据。如果不进行溢写磁盘，Reduce节点将无法获取数据，也就没办法进行Reduce任务。

    Reduce任务不需要，因为如果故障丢失数据，Reduce节点也可以从Map节点获取数据。况且，无法保证重新分配时还是在原来的节点，如果不在原来的节点，溢写本身也没有意义。

